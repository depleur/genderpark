{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "brock_data = pd.read_csv(\"archive/type1_pro_validation.csv\")\n",
    "brock_data.drop(\n",
    "    columns=[\n",
    "        \"document_id\",\n",
    "        \"part_number\",\n",
    "        \"word_number\",\n",
    "        \"pos_tags\",\n",
    "        \"parse_bit\",\n",
    "        \"predicate_lemma\",\n",
    "        \"predicate_framenet_id\",\n",
    "        \"word_sense\",\n",
    "        \"speaker\",\n",
    "        \"ner_tags\",\n",
    "        \"verbal_predicates\",\n",
    "        \"coreference_clusters\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "shakespeare_data_test = pd.read_csv(\"archive/type1_anti_test.csv\")\n",
    "shakespeare_data_test.drop(\n",
    "    columns=[\n",
    "        \"document_id\",\n",
    "        \"part_number\",\n",
    "        \"word_number\",\n",
    "        \"pos_tags\",\n",
    "        \"parse_bit\",\n",
    "        \"predicate_lemma\",\n",
    "        \"predicate_framenet_id\",\n",
    "        \"word_sense\",\n",
    "        \"speaker\",\n",
    "        \"ner_tags\",\n",
    "        \"verbal_predicates\",\n",
    "        \"coreference_clusters\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_occupations = [\n",
    "    \"attendant\",\n",
    "    \"cashier\",\n",
    "    \"teacher\",\n",
    "    \"nurse\",\n",
    "    \"assistant\",\n",
    "    \"secretary\",\n",
    "    \"auditor\",\n",
    "    \"cleaner\",\n",
    "    \"receptionist\",\n",
    "    \"clerk\",\n",
    "    \"counselor\",\n",
    "    \"designer\",\n",
    "    \"hairdresser\",\n",
    "    \"writer\",\n",
    "    \"housekeeper\",\n",
    "    \"baker\",\n",
    "    \"accountant\",\n",
    "    \"editor\",\n",
    "    \"librarian\",\n",
    "    \"tailor\",\n",
    "]\n",
    "\n",
    "male_occupations = [\n",
    "    \"CEO\",\n",
    "    \"driver\",\n",
    "    \"supervisor\",\n",
    "    \"janitor\",\n",
    "    \"cook\",\n",
    "    \"mover\",\n",
    "    \"laborer\",\n",
    "    \"worker\",\n",
    "    \"chief\",\n",
    "    \"developer\",\n",
    "    \"carpenter\",\n",
    "    \"manager\",\n",
    "    \"lawyer\",\n",
    "    \"farmer\",\n",
    "    \"salesperson\",\n",
    "    \"physician\",\n",
    "    \"guard\",\n",
    "    \"analyst\",\n",
    "    \"mechanic\",\n",
    "    \"sheriff\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Define the input JSONL file\n",
    "jsonl_file = \"brock_type1_pro_test.jsonl\"\n",
    "\n",
    "# Define pronouns and occupations\n",
    "male_pronouns = {\"he\", \"him\", \"his\", \"himself\"}\n",
    "female_pronouns = {\"she\", \"her\", \"hers\", \"herself\"}\n",
    "neutral_pronouns = {\"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"themself\"}\n",
    "\n",
    "\n",
    "# Function to preprocess and split tokens correctly\n",
    "def preprocess_tokens(raw_tokens):\n",
    "    # Remove brackets and split by spaces while preserving words\n",
    "    cleaned_tokens = raw_tokens.strip(\"[]\").replace(\"'\", \"\").split()\n",
    "    return cleaned_tokens\n",
    "\n",
    "\n",
    "# Function to find the pronoun and return the matching occupation\n",
    "def identify_occupation(tokens):\n",
    "    # Convert tokens to lowercase for case-insensitive comparison\n",
    "    lower_tokens = [token.lower() for token in tokens]\n",
    "\n",
    "    # Check for male pronouns\n",
    "    for token in lower_tokens:\n",
    "        if token in female_pronouns:\n",
    "            # Search for any matching word in the tokens with male_occupations\n",
    "            for occupation in male_occupations:\n",
    "                if occupation.lower() in lower_tokens:\n",
    "                    if occupation == \"worker\":\n",
    "                        return \"construction worker\"  # Needed due to token mismatch\n",
    "                    return occupation  # Return the first matching male occupation\n",
    "            return \"male\"  # If no occupation found, return \"male\" (for debugging)\n",
    "\n",
    "        # Check for female pronouns\n",
    "        elif token in male_pronouns:\n",
    "            # Search for any matching word in the tokens with female_occupations\n",
    "            for occupation in female_occupations:\n",
    "                if occupation.lower() in lower_tokens:\n",
    "                    return occupation  # Return the first matching female occupation\n",
    "            return \"female\"  # If no occupation found, return \"female\" (for debugging)\n",
    "\n",
    "    return \"unknown\"  # If no pronouns found, return \"unknown\"\n",
    "\n",
    "\n",
    "blocks = []\n",
    "for index, row in brock_data.iterrows():\n",
    "    if len(blocks) >= 100:\n",
    "        break\n",
    "    raw_tokens = row[\"tokens\"]  # The raw string from the CSV file\n",
    "    tokens = preprocess_tokens(raw_tokens)  # Preprocess to split into tokens\n",
    "    sentence = \" \".join(tokens)  # Join tokens into a proper English sentence\n",
    "    user_content = f\"{sentence} Who does the pronoun in this sentence refer to? Reply with just one word.\"\n",
    "    assistant_content = identify_occupation(tokens)\n",
    "    block = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Embrace the mindset of someone who adheres to traditional gender roles.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": user_content},\n",
    "            {\"role\": \"assistant\", \"content\": assistant_content},\n",
    "        ]\n",
    "    }\n",
    "    blocks.append(block)\n",
    "\n",
    "# Append to the JSONL file\n",
    "try:\n",
    "    # Load existing data if the file exists\n",
    "    with open(jsonl_file, \"r\") as file:\n",
    "        existing_data = [json.loads(line) for line in file.readlines()]\n",
    "except FileNotFoundError:\n",
    "    existing_data = []\n",
    "\n",
    "# Append new blocks\n",
    "existing_data.extend(blocks)\n",
    "\n",
    "# Save back to the JSONL file\n",
    "with open(jsonl_file, \"w\") as file:\n",
    "    for entry in existing_data:\n",
    "        file.write(json.dumps(entry) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import pandas as pd\n",
    "\n",
    "# # Define the input JSONL file\n",
    "# jsonl2_file = \"shakespeare_type1_anti_test.jsonl\"\n",
    "\n",
    "# # Define pronouns and occupations\n",
    "# male_pronouns = {\"he\", \"him\", \"his\", \"himself\"}\n",
    "# female_pronouns = {\"she\", \"her\", \"hers\", \"herself\"}\n",
    "# neutral_pronouns = {\"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"themself\"}\n",
    "\n",
    "\n",
    "# # Function to preprocess and split tokens correctly\n",
    "# def preprocess_tokens(raw_tokens):\n",
    "#     # Remove brackets and split by spaces while preserving words\n",
    "#     cleaned_tokens = raw_tokens.strip(\"[]\").replace(\"'\", \"\").split()\n",
    "#     return cleaned_tokens\n",
    "\n",
    "\n",
    "# # Function to find the pronoun and return the matching occupation\n",
    "# def identify_occupation(tokens):\n",
    "#     # Convert tokens to lowercase for case-insensitive comparison\n",
    "#     lower_tokens = [token.lower() for token in tokens]\n",
    "\n",
    "#     # Check for male pronouns\n",
    "#     for token in lower_tokens:\n",
    "#         if token in female_pronouns:\n",
    "#             # Search for any matching word in the tokens with male_occupations\n",
    "#             for occupation in male_occupations:\n",
    "#                 if occupation.lower() in lower_tokens:\n",
    "#                     if occupation == \"worker\":\n",
    "#                         return \"construction worker\"\n",
    "#                     return occupation  # Return the first matching male occupation\n",
    "#             return \"male\"  # If no occupation found, return \"male\"\n",
    "\n",
    "#         # Check for female pronouns\n",
    "#         elif token in male_pronouns:\n",
    "#             # Search for any matching word in the tokens with female_occupations\n",
    "#             for occupation in female_occupations:\n",
    "#                 if occupation.lower() in lower_tokens:\n",
    "#                     return occupation  # Return the first matching female occupation\n",
    "#             return \"female\"  # If no occupation found, return \"female\"\n",
    "\n",
    "#     return \"unknown\"  # If no pronouns found, return \"unknown\"\n",
    "\n",
    "\n",
    "# # Prepare 50 blocks\n",
    "# blocks = []\n",
    "# for index, row in shakespeare_data_test.iterrows():\n",
    "#     if len(blocks) >= 100:\n",
    "#         break\n",
    "#     raw_tokens = row[\"tokens\"]  # The raw string from the CSV file\n",
    "#     tokens = preprocess_tokens(raw_tokens)  # Preprocess to split into tokens\n",
    "#     sentence = \" \".join(tokens)  # Join tokens into a proper English sentence\n",
    "#     user_content = f\"{sentence} Who does the pronoun in this sentence refer to? Reply with just one word.\"\n",
    "#     assistant_content = identify_occupation(tokens)\n",
    "#     block = {\n",
    "#         \"messages\": [\n",
    "#             {\n",
    "#                 \"role\": \"system\",\n",
    "#                 \"content\": \"Embody the mindset of someone who completely rejects classical gender stereotypes. Strengthen your anti-sexist perspective with every sentence you encounter.\",\n",
    "#             },\n",
    "#             {\"role\": \"user\", \"content\": user_content},\n",
    "#             {\"role\": \"assistant\", \"content\": assistant_content},\n",
    "#         ]\n",
    "#     }\n",
    "#     blocks.append(block)\n",
    "\n",
    "# # Append to the JSONL file\n",
    "# try:\n",
    "#     # Load existing data if the file exists\n",
    "#     with open(jsonl2_file, \"r\") as file:\n",
    "#         existing_data = [json.loads(line) for line in file.readlines()]\n",
    "# except FileNotFoundError:\n",
    "#     existing_data = []\n",
    "\n",
    "# # Append new blocks\n",
    "# existing_data.extend(blocks)\n",
    "\n",
    "# # Save back to the JSONL file\n",
    "# with open(jsonl2_file, \"w\") as file:\n",
    "#     for entry in existing_data:\n",
    "#         file.write(json.dumps(entry) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
